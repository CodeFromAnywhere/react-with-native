"use strict";var __awaiter=this&&this.__awaiter||function(t,e,r,o){return new(r||(r=Promise))((function(n,a){function l(t){try{u(o.next(t))}catch(t){a(t)}}function s(t){try{u(o.throw(t))}catch(t){a(t)}}function u(t){var e;t.done?n(t.value):(e=t.value,e instanceof r?e:new r((function(t){t(e)}))).then(l,s)}u((o=o.apply(t,e||[])).next())}))},__generator=this&&this.__generator||function(t,e){var r,o,n,a,l={label:0,sent:function(){if(1&n[0])throw n[1];return n[1]},trys:[],ops:[]};return a={next:s(0),throw:s(1),return:s(2)},"function"==typeof Symbol&&(a[Symbol.iterator]=function(){return this}),a;function s(a){return function(s){return function(a){if(r)throw new TypeError("Generator is already executing.");for(;l;)try{if(r=1,o&&(n=2&a[0]?o.return:a[0]?o.throw||((n=o.return)&&n.call(o),0):o.next)&&!(n=n.call(o,a[1])).done)return n;switch(o=0,n&&(a=[2&a[0],n.value]),a[0]){case 0:case 1:n=a;break;case 4:return l.label++,{value:a[1],done:!1};case 5:l.label++,o=a[1],a=[0];continue;case 7:a=l.ops.pop(),l.trys.pop();continue;default:if(!(n=l.trys,(n=n.length>0&&n[n.length-1])||6!==a[0]&&2!==a[0])){l=0;continue}if(3===a[0]&&(!n||a[1]>n[0]&&a[1]<n[3])){l.label=a[1];break}if(6===a[0]&&l.label<n[1]){l.label=n[1],n=a;break}if(n&&l.label<n[2]){l.label=n[2],l.ops.push(a);break}n[2]&&l.ops.pop(),l.trys.pop();continue}a=e.call(t,l)}catch(t){a=[6,t],o=0}finally{r=n=0}if(5&a[0])throw a[1];return{value:a[0]?a[1]:void 0,done:!0}}([a,s])}}};Object.defineProperty(exports,"__esModule",{value:!0}),exports.processChatGptPrompt=void 0;var database_1=require("database"),model_types_1=require("model-types"),controlChatGpt_1=require("./controlChatGpt"),getContextualPrompt_1=require("./getContextualPrompt"),processChatGptPrompt=function(t){return __awaiter(void 0,void 0,void 0,(function(){var e,r,o,n,a,l,s,u,c,i,p,h,f,m;return __generator(this,(function(d){switch(d.label){case 0:return e=t.commentContent,r=t.contextContent,o=t.contextualPromptSlug,n=t.customPromptContent,a=t.saveNewPromptWithName,l=t.prompt_projectRelativePath,s=t.selectionContent,u=t.isHeadless,c=t.thread,[4/*yield*/,(0,getContextualPrompt_1.getContextualPrompt)(o,n,a)];case 1:return(i=d.sent())?(p=i.promptContent.replaceAll("%context",r||"").replaceAll("%selection",s||"").replaceAll("%comment",e||""),[4/*yield*/,(0,controlChatGpt_1.controlChatGpt)(p,u)]):[2/*return*/,{isSuccessful:!1,message:"Couldn't create or find a contextual prompt"}];case 2:return h=d.sent(),f=c||(0,model_types_1.generateId)(),m={resultAssets:[],resultText:h,prompt:p,prompt_projectRelativePath:l,thread:f,contextualPromptSlug:i.slug},[4/*yield*/,database_1.db.upsert("ContextualPromptResult",m)];case 3:return d.sent(),[2/*return*/,{isSuccessful:!0,message:"Whoa",result:{text:h,thread:f}}]}}))}))};exports.processChatGptPrompt=processChatGptPrompt;
//# sourceMappingURL=processChatGptPrompt.js.map